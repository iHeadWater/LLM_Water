{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e390b0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO  2023-06-09 16:13:14,742-1d: Load pretrained SentenceTransformer: GanymedeNil/text2vec-large-chinese\n",
      "WARNING 2023-06-09 16:13:19,383-1d: No sentence-transformers model found with name C:\\Users\\silen/.cache\\torch\\sentence_transformers\\GanymedeNil_text2vec-large-chinese. Creating a new one with MEAN pooling.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_det_infer.tar to C:\\Users\\silen/.paddleocr/whl\\det\\ch\\ch_PP-OCRv3_det_infer\\ch_PP-OCRv3_det_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3.83M/3.83M [00:09<00:00, 407kiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/PP-OCRv3/chinese/ch_PP-OCRv3_rec_infer.tar to C:\\Users\\silen/.paddleocr/whl\\rec\\ch\\ch_PP-OCRv3_rec_infer\\ch_PP-OCRv3_rec_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 11.9M/11.9M [00:16<00:00, 711kiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar to C:\\Users\\silen/.paddleocr/whl\\cls\\ch_ppocr_mobile_v2.0_cls_infer\\ch_ppocr_mobile_v2.0_cls_infer.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2.19M/2.19M [00:04<00:00, 498kiB/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████| 40/40 [11:27<00:00, 17.20s/it]\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Milvus\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import UnstructuredFileLoader, TextLoader\n",
    "from loader import UnstructuredPaddleImageLoader, UnstructuredPaddlePDFLoader\n",
    "from textsplitter import ChineseTextSplitter\n",
    "from configs.model_config import *\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"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\"\n",
    "\n",
    "def write_check_file(filepath, docs):\n",
    "    folder_path = os.path.join(os.path.dirname(filepath), \"tmp_files\")\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    fp = os.path.join(folder_path, 'load_file.txt')\n",
    "    with open(fp, 'a+', encoding='utf-8') as fout:\n",
    "        fout.write(\"filepath=%s,len=%s\" % (filepath, len(docs)))\n",
    "        fout.write('\\n')\n",
    "        for i in docs:\n",
    "            fout.write(str(i))\n",
    "            fout.write('\\n')\n",
    "        fout.close()\n",
    "# SENTENCE_SIZE = 10000000\n",
    "def load_file(filepath, sentence_size=SENTENCE_SIZE):\n",
    "    if filepath.lower().endswith(\".md\"):\n",
    "        loader = UnstructuredFileLoader(filepath, mode=\"elements\")\n",
    "        docs = loader.load()\n",
    "    elif filepath.lower().endswith(\".txt\"):\n",
    "        loader = TextLoader(filepath, autodetect_encoding=True)\n",
    "        textsplitter = ChineseTextSplitter(pdf=False, sentence_size=sentence_size)\n",
    "        docs = loader.load_and_split(textsplitter)\n",
    "    elif filepath.lower().endswith(\".pdf\"):\n",
    "        loader = UnstructuredPaddlePDFLoader(filepath)\n",
    "        textsplitter = ChineseTextSplitter(pdf=True, sentence_size=sentence_size)\n",
    "        docs = loader.load_and_split(textsplitter)\n",
    "    elif filepath.lower().endswith(\".jpg\") or filepath.lower().endswith(\".png\"):\n",
    "        loader = UnstructuredPaddleImageLoader(filepath, mode=\"elements\")\n",
    "        textsplitter = ChineseTextSplitter(pdf=False, sentence_size=sentence_size)\n",
    "        docs = loader.load_and_split(text_splitter=textsplitter)\n",
    "    else:\n",
    "        loader = UnstructuredFileLoader(filepath, mode=\"elements\")\n",
    "        textsplitter = ChineseTextSplitter(pdf=False, sentence_size=sentence_size)\n",
    "        docs = loader.load_and_split(text_splitter=textsplitter)\n",
    "    write_check_file(filepath, docs)\n",
    "    return docs\n",
    "\n",
    "# embeddings = OpenAIEmbeddings()\n",
    "embedding_model: str = EMBEDDING_MODEL\n",
    "embedding_device = EMBEDDING_DEVICE\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embedding_model_dict[embedding_model], model_kwargs={'device': embedding_device})\n",
    "\n",
    "docs = load_file(\"./Chinese_Smart_Water.pdf\", SENTENCE_SIZE)\n",
    "# docs = load_file(\"./English.txt\", SENTENCE_SIZE)\n",
    "vector_db = Milvus.from_documents(\n",
    "    docs,\n",
    "    embeddings,\n",
    "    connection_args={\"host\": \"localhost\", \"port\": \"19530\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22a396f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.16it/s]\n"
     ]
    }
   ],
   "source": [
    "query = \"智慧水利可能面临的问题？\"\n",
    "docs = vector_db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4420a9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 通过智慧水利建设，构建新时代的水利公共服务体系。\n"
     ]
    }
   ],
   "source": [
    "print(docs[3].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8726665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='3存在问题近年来的水利信息化建设虽然取得了较大成绩，智慧水利建设 已进行了积极探索，但水利行业总体上还处于智慧水利建设的起步智慧行业相比，与推进国家水治理体系和治理能力现代化的需求相 比，在以下几个方面都存在较大差距。', metadata={'source': './Chinese_Smart_Water.pdf'}), Document(page_content='智慧水利是智慧社会的重要组成部分，是新时代水利信息化 发展的更高阶段，是水利现代化的前提条件，是推动水治理能力 现代化建设的客观要求。', metadata={'source': './Chinese_Smart_Water.pdf'}), Document(page_content='2 经济效益 139II: 弟一卓形劳与问题 围绕国家信息化战略、新时代水利改革发展要求以及新一代信 息技术等方面分析了水利信息化发展所面临的形势，同时从当前水利信息化基础设施建设、信息资源开发利用、网络与安全、水利业 务应用、水利网信工作管理等多方面分析了智慧水利建设的基础及 未来需要解决的主要问题。', metadata={'source': './Chinese_Smart_Water.pdf'}), Document(page_content=' 通过智慧水利建设，构建新时代的水利公共服务体系。', metadata={'source': './Chinese_Smart_Water.pdf'})]\n"
     ]
    }
   ],
   "source": [
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7edf7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatglm",
   "language": "python",
   "name": "chatglm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
